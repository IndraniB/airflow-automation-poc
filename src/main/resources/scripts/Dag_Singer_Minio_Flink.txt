from airflow import DAG
from airflow.operators.bash_operator import BashOperator
from datetime import datetime, timedelta
from airflow.models import Variable
import os
from airflow.hooks.base_hook import BaseHook
from airflow.contrib.operators.slack_webhook_operator import SlackWebhookOperator


#slack_connection_id
SLACK_CONN_ID = '+AirflowConstants.SLACK_CONN_ID+'

#generate_slack_notification

def task_success_slack_alert(context):
    slack_webhook_token = BaseHook.get_connection(SLACK_CONN_ID).password
    slack_msg = """
            :green_circle: Task Successful. 
            *Task*: {task}  
            *Dag*: {+AirflowVariable.dagName+} 
            *Execution Date*: {exec_date}  
            *Log Url*: <{base_url}/admin/airflow/log?task_id={task}&dag_id={dag}&execution_date={exec_date}>
            """.format(
            task=context.get('task_instance').task_id,
            dag=context.get('task_instance').dag_id,
            ti=context.get('task_instance'),
            exec_date=context.get('execution_date'),
            base_url=Variable.get('airflow_server'),
            #base_url=configuration.conf.get('webserver', 'BASE_URL')
        )
    success_alert = SlackWebhookOperator(
        slack_msg = \"\"\",
        http_conn_id='slack',
        webhook_token=slack_webhook_token,
        message=slack_msg,
        username='+AirflowConstants.USER_NAME+')
    return success_alert.execute(context=context)

def task_failure_slack_alert(context):
    slack_webhook_token = BaseHook.get_connection(SLACK_CONN_ID).password
    slack_msg = """
            :red_circle: Task Failed. 
            *Task*: {task}  
            *Dag*: {dag} 
            *Execution Time*: {exec_date} 
            *Log Url*: <{base_url}/admin/airflow/log?task_id={task}&dag_id={dag}&execution_date={exec_date}>
            \"\"\".format(
            task=context.get('task_instance').task_id,
            dag=context.get('task_instance').dag_id,
            ti=context.get('task_instance'),
            exec_date=context.get('execution_date'),
            base_url=Variable.get('airflow_server'),
        )
    failure_alert = SlackWebhookOperator(
        task_id='slack_test',
        http_conn_id='+AirflowConstants.SLACK_CONN_ID+',
        webhook_token=slack_webhook_token,
        message=slack_msg ,
        username='+AirflowConstants.USER_NAME+')
    return failure_alert.execute(context=context)
    
    
 def task_retry_slack_alert(context):
    slack_webhook_token = BaseHook.get_connection(SLACK_CONN_ID).password
    slack_msg = """
            :blue_circle: Task Retry. 
            *Task*: {task}  
            *Dag*: {dag} 
            *Execution Time*: {exec_date} 
            *Log Url*: <{base_url}/admin/airflow/log?task_id={task}&dag_id={dag}&execution_date={exec_date}>
            """.format(
            task=context.get('task_instance').task_id,
            dag=context.get('task_instance').dag_id,
            ti=context.get('task_instance'),
            exec_date=context.get('execution_date'),
            base_url=Variable.get('airflow_server'),
            #base_url=configuration.conf.get('webserver', 'BASE_URL'),
        )
    retry_alert = SlackWebhookOperator(
        task_id='slack_test',
        http_conn_id='+AirflowConstants.SLACK_CONN_ID+',
        webhook_token=slack_webhook_token,
        message=slack_msg ,
        username='+AirflowConstants.USER_NAME+')
    return retry_alert.execute(context=context)
    
 def task_sla_slack_alert(dag_id):
    slack_webhook_token = BaseHook.get_connection(SLACK_CONN_ID).password
    slack_msg = """
            :orange_circle: Task SLA crossed.  
            *Dag*: {dag} 
            """.format(dag=dag_id)
    sla_alert = SlackWebhookOperator(
        task_id='slack_test',
        http_conn_id='+AirflowConstants.SLACK_CONN_ID+',
        webhook_token=slack_webhook_token,
        message=slack_msg ,
        username='+AirflowConstants.USER_NAME+')
    return sla_alert.execute(dag_id=dag_id)
 
 default_args = {
    'owner': '+AirflowVariable.owner+',
    'depends_on_past': +AirflowVariable.depends_on_past+,
    'start_date': datetime(2020, 8, 13),
    'on_success_callback': task_success_slack_alert,
    'on_failure_callback': task_failure_slack_alert,
    'on_retry_callback': task_retry_slack_alert,
    'email': ['+AirflowVariable.email+'],
    'email_on_failure': +AirflowVariable.email_on_failure+,
    'email_on_retry': +AirflowVariable.email_on_retry+,
    'sla': timedelta(milliseconds=1),
    'retries': +AirflowVariable.retries+,
    'retry_delay': timedelta(minutes=1),
}
 
#file paths
filename=''
file_path ='+AirflowConstants.file_path+'
mysql_config_path='+AirflowConstants.mysql_config_path+'
epai_config_path='+AirflowConstants.epai_config_path+'
minio_sdk_path='+AirflowConstants.minio_sdk_path+'

#commands
singer_bash_cmd='cd /home/dmaas/singerwd/files/; ~/.virtualenvs/tap-exchangeratesapi/bin/tap-exchangeratesapi -c ' + epai_config_path + '/' + 'tap-config.json | ~/.virtualenvs/target-csv/bin/target-csv'

dag = DAG(
    'singer-minio-flink', default_args=default_args, schedule_interval=timedelta(1))


<< ADD TASKS HERE >>

# getting filename		
files_in_directory = os.listdir(file_path)
for file in files_in_directory:
    if file.startswith("exchange"):
        filename=file
 
<< ADD TASKS PRIORITY HERE >>